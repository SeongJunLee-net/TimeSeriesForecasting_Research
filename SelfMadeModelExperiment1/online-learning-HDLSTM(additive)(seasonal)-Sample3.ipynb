{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a9943a",
   "metadata": {},
   "source": [
    "<font color = blue><font size = 6> H(ALF)DLSTM </font></font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e0a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4383c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjlee/sj_virtual/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_forecasting.metrics import SMAPE\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch import FloatTensor\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda834c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.220168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.221584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.185184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.173464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38875</th>\n",
       "      <td>0.166704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38876</th>\n",
       "      <td>0.172936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38877</th>\n",
       "      <td>0.172976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38878</th>\n",
       "      <td>0.169264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38879</th>\n",
       "      <td>0.175408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38880 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          value\n",
       "0      0.220168\n",
       "1      0.221584\n",
       "2      0.205680\n",
       "3      0.185184\n",
       "4      0.173464\n",
       "...         ...\n",
       "38875  0.166704\n",
       "38876  0.172936\n",
       "38877  0.172976\n",
       "38878  0.169264\n",
       "38879  0.175408\n",
       "\n",
       "[38880 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_col = ['volumn']\n",
    "data = pd.read_csv('../../traffic/data/3.csv',usecols=use_col)\n",
    "data.rename({'volumn':'value'},axis=1,inplace=True)\n",
    "data['value'] = data['value'] * 8 / 1000000\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a2cfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/hdd_1/sjlee/Paper_Project/SelfMadeModel/online_learning_seq2seq']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "import os\n",
    "config = configparser.ConfigParser()\n",
    "config['online_learning_seq2seq']= {\n",
    "    'input_size':1,\n",
    "    'num_layers':1,\n",
    "    'hidden_size':16,\n",
    "}\n",
    "with open('online_learning_seq2seq','w') as f:\n",
    "    config.write(f)\n",
    "    \n",
    "config.read(os.getcwd()+os.sep+'online_learning_seq2seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c35afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seasonal_Encoder(nn.Module):\n",
    "    def __init__(self,configs):\n",
    "        super(Seasonal_Encoder,self).__init__()\n",
    "        self.input_size = int(configs['online_learning_seq2seq']['input_size'])\n",
    "        # input의 feature dimension을 넣어주어야 한다\n",
    "        self.hidden_size = int(configs['online_learning_seq2seq']['hidden_size'])\n",
    "        # 내부에서 feature dimension을 어떻게 바꿔주고 싶은지 넣어주면 된다\n",
    "        # 가령 mxn matrix가 입력으로 들어왔을때 hidden size를 h라 한다면 mxh의 크기로 바꾼다\n",
    "        self.num_layers = int(configs['online_learning_seq2seq']['num_layers'])\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size,hidden_size = self.hidden_size,\n",
    "                           num_layers = self.num_layers,batch_first = True)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        lstm_out,hidden = self.lstm(x) \n",
    "        #lstm의 output으로 나오는 hidden_state는 마지막 hidden_state값이다\n",
    "        # hidden에는 튜플형태로 hidden_state와 cell_state가 둘다 포함돼있다\n",
    "        return lstm_out,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4a3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seasonal_Decoder(nn.Module):\n",
    "    def __init__(self,configs):\n",
    "        super(Seasonal_Decoder,self).__init__()\n",
    "        self.input_size = int(configs['online_learning_seq2seq']['input_size'])\n",
    "        # input의 feature dimension을 넣어주어야 한다\n",
    "        self.hidden_size = int(configs['online_learning_seq2seq']['hidden_size'])\n",
    "        # 내부에서 feature dimension을 어떻게 바꿔주고 싶은지 넣어주면 된다\n",
    "        # 가령 mxn matrix가 입력으로 들어왔을때 hidden size를 h라 한다면 mxh의 크기로 바꾼다\n",
    "        self.num_layers = int(configs['online_learning_seq2seq']['num_layers'])\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size,hidden_size = self.hidden_size,\n",
    "                           num_layers = self.num_layers,batch_first = True)\n",
    "        self.linear = nn.Linear(self.hidden_size,self.input_size)\n",
    "        \n",
    "    def forward(self,x,encoder_hidden):\n",
    "\n",
    "        lstm_out,_ = self.lstm(x,encoder_hidden)\n",
    "        \n",
    "        output = self.linear(lstm_out)\n",
    "\n",
    "        return output,_\n",
    "# 정리하자면 우리가 정답을 알고 있는 시점에서 1시점 전까지의 데이터를 encoder로 넣고\n",
    "# 알고 있는 마지막시점 정보와 encoder에 넣어서 나온 hidden state를 넣어줌으로써 다음시점을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de257ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup= (1,2)\n",
    "len(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e64cc807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        \n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "       \n",
    "        x = self.avg(x.permute(0,2,1))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa2d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class series_decomp(nn.Module):\n",
    "    \"statsmodels.tsa의 seasonal_decompose와 역할이 똑같다\"\n",
    "    def __init__(self,kernel_size):\n",
    "        super(series_decomp,self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size,stride = 1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        moving_mean = self.moving_avg(x) #output은 (batch,sequence_length,input_size)\n",
    "        res = x - moving_mean \n",
    "        # Classical ma중에서 additive model\n",
    "\n",
    "        return res,moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f07bde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq(nn.Module):\n",
    "    def __init__(self,configs):\n",
    "        super(seq2seq,self).__init__()\n",
    "        self.device = torch.device('cuda:0')\n",
    "        self.season_encoder = Seasonal_Encoder(configs)\n",
    "        self.season_decoder = Seasonal_Decoder(configs)\n",
    "        \n",
    "        self.Linear_Trend = nn.Linear(1440,1)\n",
    "        \n",
    "        kernel_size = 25\n",
    "        self.decomposition = series_decomp(kernel_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        div_factor = x[:,-1,:].view(-1,1,1)\n",
    "        x = x-div_factor\n",
    "        outputs = torch.zeros(x.size(0),1,1) # feature가1개고 target도 1개인 데이터\n",
    "        x = x.permute(0,2,1)\n",
    "        seasonal_init,trend_init = self.decomposition(x) # res = seasonality 를 moving_mean은 trend를 의미함\n",
    "        seasonal_init,trend_init = seasonal_init.permute(0,2,1).to(self.device), trend_init.to(self.device) \n",
    "\n",
    "        _,final_season_hidden = self.season_encoder(seasonal_init)\n",
    "        season_output,_ = self.season_decoder(x = seasonal_init[:,-1,:].view(-1,1,1),encoder_hidden = final_season_hidden)\n",
    "        trend_output = self.Linear_Trend(trend_init)\n",
    "        \n",
    "        output = trend_output+season_output+div_factor\n",
    "        \n",
    "        return output,season_output,trend_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffb3b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data(x,sequence_length,pred_len):\n",
    "    seq_list = []\n",
    "    target_list = []\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    if (type(x)==list)|(type(x)==np.ndarray):\n",
    "        for i in range(len(x)-sequence_length):\n",
    "            seq_list.append(x[i:i+sequence_length].values)\n",
    "            target_list.append(x[i+sequence_length])\n",
    "    \n",
    "    if (type(x) == pd.Series)|(type(x) == pd.DataFrame):\n",
    "        for i in range(len(x)-sequence_length):\n",
    "            seq_list.append(x.iloc[i:i+sequence_length].values)\n",
    "            target_list.append(x.iloc[i+sequence_length])\n",
    "\n",
    "#             if i == 0:\n",
    "#                  print(x.iloc[i:i+sequence_length].values)\n",
    "#                  print(y[i+sequence_length:i+sequence_length+pred_len].values)\n",
    "            #print(x[i+sequence_length:i+sequence_length+pred_len].values.shape)\n",
    "    else:\n",
    "        print('error')\n",
    "\n",
    "    return FloatTensor(seq_list).view(-1,1,sequence_length).to(device),FloatTensor(target_list).unsqueeze(1).view(-1,1,pred_len).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8760a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_536706/197408478.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  return FloatTensor(seq_list).view(-1,1,sequence_length).to(device),FloatTensor(target_list).unsqueeze(1).view(-1,1,pred_len).to(device)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 1440\n",
    "pred_len = 1\n",
    "split= 10080\n",
    "x_data = pd.DataFrame({'value':data.iloc[:-split].values.reshape(-1)})\n",
    "x_seq,target = seq_data(x=x_data,sequence_length=sequence_length,pred_len=pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b0c4410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2202, 0.2216, 0.2057,  ..., 0.2027, 0.1702, 0.1716]],\n",
       "\n",
       "        [[0.2216, 0.2057, 0.1852,  ..., 0.1702, 0.1716, 0.2092]],\n",
       "\n",
       "        [[0.2057, 0.1852, 0.1735,  ..., 0.1716, 0.2092, 0.2202]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1641, 0.1660, 0.1776,  ..., 0.1784, 0.1696, 0.1720]],\n",
       "\n",
       "        [[0.1660, 0.1776, 0.2252,  ..., 0.1696, 0.1720, 0.1768]],\n",
       "\n",
       "        [[0.1776, 0.2252, 0.2034,  ..., 0.1720, 0.1768, 0.1615]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e59574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2092]],\n",
       "\n",
       "        [[0.2202]],\n",
       "\n",
       "        [[0.2011]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1768]],\n",
       "\n",
       "        [[0.1615]],\n",
       "\n",
       "        [[0.1736]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d04aa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "train_dataset = TensorDataset(x_seq,target)\n",
    "training = DataLoader(train_dataset,batch_size=batch_size)\n",
    "model = seq2seq(config).to(device)\n",
    "optimizer = Adam(model.parameters(),1e-3)\n",
    "criterion = SMAPE()\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: 0.95 ** epoch,verbose = True)\n",
    "                                       # epoch마다 learning rate에 곱해지는 값이 제곱수로 늘어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "009451dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb342d95a10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb4a221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2202, 0.2216, 0.2057,  ..., 0.2027, 0.1702, 0.1716]],\n",
       "\n",
       "        [[0.2216, 0.2057, 0.1852,  ..., 0.1702, 0.1716, 0.2092]],\n",
       "\n",
       "        [[0.2057, 0.1852, 0.1735,  ..., 0.1716, 0.2092, 0.2202]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1641, 0.1660, 0.1776,  ..., 0.1784, 0.1696, 0.1720]],\n",
       "\n",
       "        [[0.1660, 0.1776, 0.2252,  ..., 0.1696, 0.1720, 0.1768]],\n",
       "\n",
       "        [[0.1776, 0.2252, 0.2034,  ..., 0.1720, 0.1768, 0.1615]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bc85b0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.5000e-04.\n",
      "smape 38.69435307575248 %\n",
      "Adjusting learning rate of group 0 to 9.0250e-04.\n",
      "smape 24.0331137694462 %\n",
      "Adjusting learning rate of group 0 to 8.5737e-04.\n",
      "smape 30.278413172005216 %\n",
      "Adjusting learning rate of group 0 to 8.1451e-04.\n",
      "smape 26.104998205576024 %\n",
      "Adjusting learning rate of group 0 to 7.7378e-04.\n",
      "smape 29.074402201419687 %\n",
      "Adjusting learning rate of group 0 to 7.3509e-04.\n",
      "smape 21.612562930200532 %\n",
      "Adjusting learning rate of group 0 to 6.9834e-04.\n",
      "smape 25.870033995798458 %\n",
      "Adjusting learning rate of group 0 to 6.6342e-04.\n",
      "smape 22.32952334988884 %\n",
      "Adjusting learning rate of group 0 to 6.3025e-04.\n",
      "smape 25.388252438421834 %\n",
      "Adjusting learning rate of group 0 to 5.9874e-04.\n",
      "smape 20.189973124199444 %\n",
      "Adjusting learning rate of group 0 to 5.6880e-04.\n",
      "smape 17.456285674669587 %\n",
      "Adjusting learning rate of group 0 to 5.4036e-04.\n",
      "smape 19.186048963439394 %\n",
      "Adjusting learning rate of group 0 to 5.1334e-04.\n",
      "smape 18.382468650564114 %\n",
      "Adjusting learning rate of group 0 to 4.8767e-04.\n",
      "smape 15.929429144190069 %\n",
      "Adjusting learning rate of group 0 to 4.6329e-04.\n",
      "smape 15.534023115335152 %\n",
      "Adjusting learning rate of group 0 to 4.4013e-04.\n",
      "smape 16.27562025529251 %\n",
      "Adjusting learning rate of group 0 to 4.1812e-04.\n",
      "smape 14.030251438506166 %\n",
      "Adjusting learning rate of group 0 to 3.9721e-04.\n",
      "smape 14.098737956574785 %\n",
      "Adjusting learning rate of group 0 to 3.7735e-04.\n",
      "smape 15.08710455955469 %\n",
      "Adjusting learning rate of group 0 to 3.5849e-04.\n",
      "smape 12.874758039650164 %\n",
      "Adjusting learning rate of group 0 to 3.4056e-04.\n",
      "smape 14.911318053191867 %\n",
      "Adjusting learning rate of group 0 to 3.2353e-04.\n",
      "smape 12.929588926204463 %\n",
      "Adjusting learning rate of group 0 to 3.0736e-04.\n",
      "smape 12.38918516893833 %\n",
      "Adjusting learning rate of group 0 to 2.9199e-04.\n",
      "smape 12.008748291528713 %\n",
      "Adjusting learning rate of group 0 to 2.7739e-04.\n",
      "smape 11.831161083098044 %\n",
      "Adjusting learning rate of group 0 to 2.6352e-04.\n",
      "smape 11.33466190631278 %\n",
      "Adjusting learning rate of group 0 to 2.5034e-04.\n",
      "smape 11.873803436320427 %\n",
      "Adjusting learning rate of group 0 to 2.3783e-04.\n",
      "smape 11.46994880678361 %\n",
      "Adjusting learning rate of group 0 to 2.2594e-04.\n",
      "smape 11.279720365565423 %\n",
      "Adjusting learning rate of group 0 to 2.1464e-04.\n",
      "smape 11.202405889393294 %\n",
      "Adjusting learning rate of group 0 to 2.0391e-04.\n",
      "smape 12.029973376128408 %\n",
      "Adjusting learning rate of group 0 to 1.9371e-04.\n",
      "smape 12.37821231416443 %\n",
      "Adjusting learning rate of group 0 to 1.8403e-04.\n",
      "smape 11.845092269760823 %\n",
      "Adjusting learning rate of group 0 to 1.7482e-04.\n",
      "smape 11.57671417104222 %\n",
      "Adjusting learning rate of group 0 to 1.6608e-04.\n",
      "smape 11.120297111875828 %\n",
      "Adjusting learning rate of group 0 to 1.5778e-04.\n",
      "smape 11.208563431313163 %\n",
      "Adjusting learning rate of group 0 to 1.4989e-04.\n",
      "smape 11.693722878893215 %\n",
      "Adjusting learning rate of group 0 to 1.4240e-04.\n",
      "smape 11.87736763460943 %\n",
      "Adjusting learning rate of group 0 to 1.3528e-04.\n",
      "smape 12.638832450087307 %\n",
      "Adjusting learning rate of group 0 to 1.2851e-04.\n",
      "smape 12.803953710442398 %\n",
      "Adjusting learning rate of group 0 to 1.2209e-04.\n",
      "smape 13.331714759618915 %\n",
      "Adjusting learning rate of group 0 to 1.1598e-04.\n",
      "smape 12.688173417720877 %\n",
      "Adjusting learning rate of group 0 to 1.1018e-04.\n",
      "smape 12.567915644562037 %\n",
      "Adjusting learning rate of group 0 to 1.0467e-04.\n",
      "smape 11.803410414889543 %\n",
      "Adjusting learning rate of group 0 to 9.9440e-05.\n",
      "smape 12.214885144467242 %\n",
      "Adjusting learning rate of group 0 to 9.4468e-05.\n",
      "smape 11.789188859058402 %\n",
      "Adjusting learning rate of group 0 to 8.9745e-05.\n",
      "smape 12.140991954427015 %\n",
      "Adjusting learning rate of group 0 to 8.5258e-05.\n",
      "smape 11.555748353140396 %\n",
      "Adjusting learning rate of group 0 to 8.0995e-05.\n",
      "smape 11.347649273032333 %\n",
      "Adjusting learning rate of group 0 to 7.6945e-05.\n",
      "smape 10.646109111737786 %\n",
      "Adjusting learning rate of group 0 to 7.3098e-05.\n",
      "smape 11.389584661575785 %\n",
      "Adjusting learning rate of group 0 to 6.9443e-05.\n",
      "smape 11.3154370965142 %\n",
      "Adjusting learning rate of group 0 to 6.5971e-05.\n",
      "smape 11.107150564155384 %\n",
      "Adjusting learning rate of group 0 to 6.2672e-05.\n",
      "smape 10.949345390524782 %\n",
      "Adjusting learning rate of group 0 to 5.9539e-05.\n",
      "smape 10.786996620614627 %\n",
      "Adjusting learning rate of group 0 to 5.6562e-05.\n",
      "smape 10.775107313056438 %\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 7.79 GiB total capacity; 221.08 MiB already allocated; 69.56 MiB free; 288.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out,tg)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# optimizer 최적화\u001b[39;00m\n\u001b[1;32m     22\u001b[0m ss_list\u001b[38;5;241m.\u001b[39mappend(ss)\n",
      "File \u001b[0;32m~/sj_virtual/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sj_virtual/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 7.79 GiB total capacity; 221.08 MiB already allocated; 69.56 MiB free; 288.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "out_list = []\n",
    "loss_list = []\n",
    "ss_list = []\n",
    "tr_list = []\n",
    "n = len(training)\n",
    "for i in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for seq,tg in training:\n",
    "        \n",
    "        seq = seq.permute(0,2,1)\n",
    "#         print(seq)\n",
    "        out,ss,tr = model(seq)\n",
    "#         print(out)\n",
    "        loss = criterion(out,tg)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step() # optimizer 최적화\n",
    "        \n",
    "        ss_list.append(ss)\n",
    "        tr_list.append(tr)\n",
    "        \n",
    "        running_loss = running_loss + loss.item()        \n",
    "    scheduler.step() #schedular update \n",
    "    loss_list.append(running_loss/n)\n",
    "    print('smape',running_loss/n*100,'%')                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343020de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ss_list[26])\n",
    "print(tr_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf55fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "X = data.iloc[:-split]\n",
    "target = data.iloc[-split:]\n",
    "pred_list = []\n",
    "time_list = []\n",
    "\n",
    "for idx in range(split):\n",
    "    running_loss = 0.0\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    for epochs in range(num_epochs):\n",
    "        if idx == 0: \n",
    "            new_train = torch.FloatTensor(\n",
    "                [X.iloc[-sequence_length-1:-1].values] # 현재 알고 있는 마지막 정답에서 하나 이전 값 까지가 Training Data\n",
    "            ).view(1,-1,1).to(device)\n",
    "\n",
    "            tg = FloatTensor(X.iloc[-1]).view(1,1,1).to(device)\n",
    "           \n",
    "        elif idx == 1:\n",
    "            new_train = torch.FloatTensor(\n",
    "                [X.iloc[-sequence_length-1+idx:].values] # 현재 알고 있는 마지막 정답에서 하나 이전 값 까지가 Training Data\n",
    "            ).view(1,-1,1).to(device)\n",
    "            \n",
    "            tg = FloatTensor(target.iloc[0]).view(1,1,1).to(device)\n",
    "        else:        \n",
    "            if idx <= sequence_length:# idx가 1보다는 크고 sequence_length보단 작거나 같은경우\n",
    "                new_train = torch.FloatTensor(\n",
    "                    [pd.concat([X.iloc[-sequence_length+idx-1:],target.iloc[0:idx-1]],axis=0,ignore_index=True).values]\n",
    "                    ).view(1,-1,1).to(device)\n",
    "\n",
    "                tg = FloatTensor(target.iloc[idx-1]).view(1,1,1).to(device)\n",
    "\n",
    "            elif idx > sequence_length:\n",
    "                new_train = torch.FloatTensor(\n",
    "                    [target.iloc[idx-sequence_length-1:idx-1].values]\n",
    "                    ).view(1,-1,1).to(device)\n",
    "                \n",
    "                tg = FloatTensor(target.iloc[idx-1]).view(1,1,1).to(device)\n",
    "\n",
    "        out,_,_ = model(new_train) # 예측완료\n",
    "\n",
    "        loss = criterion(out,tg)# 예측값과 타겟값의 비교\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step() # optimizer 최적화\n",
    "            \n",
    "        running_loss = running_loss + loss.item()\n",
    "    \n",
    "    real_input = torch.cat([new_train[:,1:,:],tg],dim=1)\n",
    "    \n",
    "    with torch.no_grad(): #model.eval()과 train()은 레이어에만 영향을 준다 with문이 끝나면 자동 종료\n",
    "        model.eval()\n",
    "        real_out,_,_ = model(real_input)\n",
    "    model.train()        \n",
    "    print('SMAPE',(running_loss/100)*100,'%')\n",
    "    end = time.time()\n",
    "    pred_list.append(real_out.cpu().view(1).item())\n",
    "    time_list.append(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b47fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20588b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=list(target.values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6369f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.iloc[-split:]\n",
    "target = target.values.reshape(-1,1)\n",
    "score=SMAPE()(FloatTensor(np.array(pred_list).reshape(-1,1)),FloatTensor(target))*100\n",
    "print('SMAPE',score.item(),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fb156",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf713277",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d553644",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,1,figsize=(12,8))\n",
    "axes.plot(np.arange(1,10081),pred_list[:],label='prediction')\n",
    "axes.plot(np.arange(1,10081),target[:],label='target')\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c292f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,1,figsize=(12,8))\n",
    "axes.plot(np.arange(1,61),pred_list[-60:],label='prediction')\n",
    "axes.plot(np.arange(1,61),target[-60:],label='target')\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a566ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,1,figsize=(12,8))\n",
    "axes.plot(np.arange(2200,2250),pred_list[2200:2250],label='prediction')\n",
    "axes.plot(np.arange(2200,2250),target[2200:2250],label='target')\n",
    "axes.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sj_virtual",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
